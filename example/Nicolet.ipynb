{
 "metadata": {
  "name": "",
  "signature": "sha256:14d442fddcb31ebabe5e9a13afd0ec5abbbe76a5f26d76c5e3056f63107ce1ab"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "#sys.path.append('D:/ATLData/Documents/GitHub/GFLOW_utils')\n",
      "sys.path.append('..')\n",
      "import lsmaker as lsm\n",
      "import GISio"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls = lsm.linesinks('Nicolet_lines.xml')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####First step is to run *preprocess_arcpy()*, which performs a few steps not implemented in the Python GIS modules\n",
      "This step produces the files listed in the **`<preprocessed/>`** section of the XML input file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#ls.preprocess_arcpy()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#ls.prototype()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "linesinks instance has no attribute 'df'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-4-92bda730c9fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprototype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32mD:\\ATLData\\Documents\\GitHub\\GFLOW_utils\\lsmaker.py\u001b[0m in \u001b[0;36mprototype\u001b[1;34m(self, nftol, fftol)\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[0mnlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnftol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 366\u001b[1;33m             \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplify_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnearfield_tolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfarfield_tolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfftol\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m             \u001b[1;31m# count the number of lines with distance tolerance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mD:\\ATLData\\Documents\\GitHub\\GFLOW_utils\\lsmaker.py\u001b[0m in \u001b[0;36msimplify_lines\u001b[1;34m(self, nearfield_tolerance, farfield_tolerance)\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[0mfarfield_tolerance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfarfield_tolerance\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfarfield\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'farfield'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'true'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfarfield\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mAttributeError\u001b[0m: linesinks instance has no attribute 'df'"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls.preprocess()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Assembling input...\n",
        "\n",
        "reading preprocessed/flowlines_clipped.shp...\n",
        "--> building dataframe... (may take a while for large shapefiles)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "reading shps/NHDPlus04/NHDPlusAttributes/elevslope.dbf..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "--> building dataframe... (may take a while for large shapefiles)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "reading shps/NHDPlus07/NHDPlusAttributes/elevslope.dbf...\n",
        "--> building dataframe... (may take a while for large shapefiles)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "reading shps/NHDPlus04/NHDPlusAttributes/PlusFlowlineVAA.dbf...\n",
        "--> building dataframe... (may take a while for large shapefiles)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "reading shps/NHDPlus07/NHDPlusAttributes/PlusFlowlineVAA.dbf...\n",
        "--> building dataframe... (may take a while for large shapefiles)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "reading preprocessed/waterbodies_clipped.shp...\n",
        "--> building dataframe... (may take a while for large shapefiles)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "reading shps/Nicolet_north_NF.shp..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "--> building dataframe... (may take a while for large shapefiles)\n",
        "\n",
        "reading preprocessed/ff_cutout.shp...\n",
        "--> building dataframe... (may take a while for large shapefiles)\n",
        "\n",
        "identifying farfield and nearfield linesinks...\n",
        "removing farfield streams lower than 2 order..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "dropping waterbodies that are not lakes larger than 1.0...\n",
        "merging waterbodies with coincident boundaries...\n",
        "converting lake exterior polygons to lines..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "merging flowline and waterbody datasets..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Done with preprocessing.\n",
        "writing preprocessed/lines.shp..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "copying shps/Nicolet_north_NF.prj --> preprocessed/lines.prj..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls.makeLineSinks(shp='preprocessed/lines.shp')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "reading preprocessed/lines.shp...\n",
        "--> building dataframe... (may take a while for large shapefiles)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "simplifying NHD linework geometries..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Assigning attributes for GFLOW input..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "reading preprocessed/waterbodies_clipped_points.shp..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "--> building dataframe... (may take a while for large shapefiles)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "13395725"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[(331881.12656733964, 5074589.484747184), (331910.6268706784, 5074934.264720128)]\n",
        "[ -29.50030285 -344.77996729]\n",
        "[-1. -1.]\n",
        "[-14.14213562 -14.14213562]\n",
        "[(331881.12656733964, 5074589.484747184), (331896.48473457084, 5074920.1225788491)]\n",
        "13395637\n",
        "[(341672.04312749207, 5083702.645163178), (341272.44262292323, 5083294.013934821)]\n",
        "[ 382.5044678   391.14883175]\n",
        "[ 1.  1.]\n",
        "[ 14.14213562  14.14213562]\n",
        "[(341672.04312749207, 5083702.645163178), (341303.68079531263, 5083325.6384670474)]\n",
        "13396449"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[(326287.76714853244, 5076374.495166003), (325798.30336456094, 5077843.442816798)]\n",
        "[  489.46377379 -1468.94762024]\n",
        "[ 1. -1.]\n",
        "[ 14.14213562 -14.14213562]\n",
        "[(326287.76714853244, 5076374.495166003), (325812.44551036594, 5077829.300650618)]\n",
        "13391953"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[(343830.9616089578, 5104320.346948502), (343827.5694161749, 5104002.822676817)]\n",
        "[   3.14293208  294.1923659 ]\n",
        "[ 1.  1.]\n",
        "[ 14.14213562  14.14213562]\n",
        "[(343830.9616089578, 5104320.346948502), (343841.96081249928, 5104040.2967182295)]\n",
        "13390755\n",
        "[(345368.54324456945, 5105193.523153277), (345596.9623907576, 5104631.221940106)]\n",
        "[-185.37442366  456.33768032]\n",
        "[-1.  1.]\n",
        "[-14.14213562  14.14213562]\n",
        "[(345368.54324456945, 5105193.523153277), (345539.77553260274, 5104751.327608576)]\n",
        "13392295\n",
        "[(344799.1401180485, 5101563.024788666), (343552.07964701834, 5102058.754011076)]\n",
        "[ 1247.06042712  -495.72920496]\n",
        "[ 1. -1.]\n",
        "[ 14.14213562 -14.14213562]\n",
        "[(344799.1401180485, 5101563.024788666), (343566.2218265527, 5102044.6118579973)]\n",
        "13395571"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[(331754.16818109644, 5088072.334746947), (331214.2808207629, 5087835.1550379945)]\n",
        "[ 515.44785913  226.44311053]\n",
        "[ 1.  1.]\n",
        "[ 14.14213562  14.14213562]\n",
        "[(331754.16818109644, 5088072.334746947), (331252.86245759449, 5087860.0337720448)]\n",
        "6844103"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[(364596.696033836, 5074653.84267313), (365074.02196697216, 5075139.536903872), (365666.2044653089, 5074901.391256949), (366590.9219340366, 5076274.813187637), (369498.1632252609, 5076817.841489259)]\n",
        "[-2851.83560217  -532.67936453]\n",
        "[-1. -1.]\n",
        "[-14.14213562 -14.14213562]\n",
        "[(364596.696033836, 5074653.84267313), (365074.02196697216, 5075139.536903872), (365666.2044653089, 5074901.391256949), (366590.9219340366, 5076274.813187637), (369428.61540058383, 5076793.3504165458)]\n",
        "6843209"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[(370537.69301233895, 5078465.843303893), (371816.0610063697, 5079989.599803478), (372512.68035624875, 5080265.054741344)]\n",
        "[-673.95842324 -266.4944286 ]\n",
        "[-1. -1.]\n",
        "[-14.14213562 -14.14213562]\n",
        "[(370537.69301233895, 5078465.843303893), (371816.0610063697, 5079989.599803478), (372475.87729398691, 5080241.9520964548)]\n",
        "6843213\n",
        "[(372364.1137505956, 5078205.157246558), (372250.86596392794, 5079508.217782544)]\n",
        "[  112.96895874 -1299.85226428]\n",
        "[ 1. -1.]\n",
        "[ 14.14213562 -14.14213562]\n",
        "[(372364.1137505956, 5078205.157246558), (372265.28692747984, 5079490.8673752155)]\n",
        "9029079"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[(335541.40557420405, 5040434.951357027), (335953.5284985453, 5040339.15027027)]\n",
        "[-412.12292013   95.80108578]\n",
        "[-1.  1.]\n",
        "[-14.14213562  14.14213562]\n",
        "[(335541.40557420405, 5040434.951357027), (335939.38635871181, 5040353.2924068728)]\n",
        "\n",
        "merging or splitting lines with only two vertices..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "number of lines in original NHD linework: 53109"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "number of simplified lines: 3831\n",
        "\n",
        "writing 3831 lines to Nicolet.lss.xml\n",
        "writing Nicolet.shp..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "copying shps/Nicolet_north_NF.prj --> Nicolet.prj..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Done!\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "C:\\Users\\aleaf\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py:245: SettingWithCopyWarning: \n",
        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
        "Try using .loc[row_indexer,col_indexer] = value instead\n",
        "\n",
        "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
        "  self.obj[key] = np.nan\n",
        "C:\\Users\\aleaf\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py:415: SettingWithCopyWarning: \n",
        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
        "Try using .loc[row_indexer,col_indexer] = value instead\n",
        "\n",
        "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
        "  self.obj[item] = s\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "np.sign([(1, -2)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls.df.ix[13391969, 'geometry'].crosses(ls.df.ix[13391717, 'geometry'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from shapely.geometry import LineString\n",
      "LineString(ls.df.ix[13391969, 'ls_coords']).intersection(ls.df.ix[13391717, 'geometry']).xy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls.df.ix[13396585, 'geometry'].crosses(ls.df.ix[13396587, 'geometry'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "shpdf = GISio.shp2df('Nicolet.shp', index='COMID')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "shpdf.index"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "comids = ls.df.index.values\n",
      "geoms = ls.df.geometry.tolist()\n",
      "\n",
      "crosses = {}\n",
      "for i, linesink in enumerate(geoms):\n",
      "    x = [comids[j] for j, g in enumerate(geoms) if linesink.crosses(g)]\n",
      "    if len(x) > 0:\n",
      "        crosses[comids[i]] = x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "crosses"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ip = ls.df.ix[167120868, 'geometry'].intersection(ls.df.ix[13391953, 'geometry']).xy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "tuple(np.ravel(ip))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls_coords = ls.df.ix[167120868, 'geometry'].xy\n",
      "ls_coords = zip(np.ravel(ls_coords[0]), np.ravel(ls_coords[1]))\n",
      "ls_coords"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls_coords.pop(-1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls_coords"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}